#Configurations file.


#  input-file  : Input file or a folder containing files. Only accepts .csv files.
#                In the case of a folder make sure that all .csv files have the same headers(contain the same data)


input-file=data

#  output-file : The output .parquet file name.

output-file=temp2.parquet

#  stats-file  :  Specify the path where the statistics file will be written. Default is in the current directory with the name stats.txt

stats-file=stats2.txt

#  parquet-size : Defines the amount of records that get written into a parquet. If the size is reached a new parquet file will be made.

parquet-size=20000000

#  headers: Manually define all headers.

#  latitude    : Define the latitude data column in your data.

latitude=Start_LocationLatitude

#  longitude   : Define the longitude data column in your data.

longitude=Start_LocationLongitude

#  time        : Define the time column in your data. Time should be in one of the more used data formats.
#

time=Start_TestTimestamp

# timezone : Enter the Id of the timezone(eg. America/New_York). Default is that times are in UTC. Not required.

# start-time : Together with end_time you can specify to make records of data only from a certain timeframe. Please make sure to use the same dateTime format as is in data.

# end-time :  Together with start_time you can specify a certain timeframe to only be valid.

# radius : Radius in meters from which uncertainty geometry is calculated. If zero then a geometryPoint is constructed. Not required.

# is-coordinate-randomized-in-uncertainty : Boolean parameter to indicate whether the coordinate is randomized inside the
# uncertainty geometry.

is-coordinate-randomized-in-uncertainty=false

# cell-location-identifier : Used as cell location identifier when radius is not defined to calculate inter-site distance

# cell-location-equality-tolerance : Used to determine whether the locations are the same by seeing if their latitude and longitude coordinate
# differences are smaller than the tolerance

# excluded : Names of columns, that do not get used in conversion.

# default-type : Define the default data type for when type cannot be determined by the examples. Default is "string". Acceptable options are: "float", "double",

# unique-strings : Define the number of unique strings allowed on a String column. Use to ease memory problems.
#                  Any unique strings that exceed this number in a column get converted into a unified class. Default value is max int.

unique-strings=10000

# columns-to-map-long : Define columns, that contain unique ID-s that are hashed. Data in these rows gets converted into unique ID-s.

# retain-hashes : Define columns, that contain unique ID-s that are hashed. In this case a new columns is created for the hashes and the original is retained.

# long-null-values : Define additional long numbers, that indicate missing data. For example "long_null_values=0,-1"

# double-null-values : Define additional double numbers, that indicate missing data.

# float-null-values : Define additional float numbers, that indicate missing data. Max int(2147483647) is sometimes used to indicate missing data

# string-null-values : Define additional string null values. Empty string ("") is automatically defined as null.

float-null-values=2147483647

####     Following column definitions should be used when you want to redefine a column type or if the converter doesn't convert a desired column.
#        When the first row doesn't contain any data, define the columns down here. Please do not modify the types of the 3 required fields.

# long-columns : Manually defined long columns. Use to retain long values in certain columns.

long-columns=

# float-columns : Manually defined float columns.

# double-columns : Manually defined double columns.

# string-columns : Manually defined string columns. Use to convert fields that are categories but typed in as number into categories.

string-columns=

# time-columns : Define columns that contain time-based information

# trajectoryID : Define the ID field for trajectory

# tokenFiles : Files, that create additional columns based on the mapping inside(input is a mapping csv with a header,
where the first column is an existing column from the data and the second column is a target column)

####    Below define extra null values for columns in the following format: columnname=value1,value2
#       Name the columns exactly as they are in the data